{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-10T08:38:57.276478200Z",
     "start_time": "2023-08-10T08:38:56.997623800Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from tokens import TOKEN_KEY, TOKEN_CX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def get_google_search_results(string, siteSearch=\"\", searchType=\"exact\", page=0, hl=\"pt-BR\", lr=\"lang_pt\"):\n",
    "    url = f'https://customsearch.googleapis.com/customsearch/v1'\n",
    "    params = {\n",
    "        \"key\": TOKEN_KEY,\n",
    "        \"cx\": TOKEN_CX,\n",
    "        \"hl\": hl,\n",
    "        \"lr\": lr,\n",
    "        \"start\": (page*10+1)\n",
    "    }\n",
    "\n",
    "    # Fill params according to search type. 'exact' uses 'exactTerms' and 'any' uses 'q',\n",
    "    # which in theory uses results that do not have the exact phrasing as in the string\n",
    "    if searchType == \"exact\":\n",
    "        params[\"exactTerms\"] = string\n",
    "    elif searchType == \"any\":\n",
    "        params[\"q\"] = string\n",
    "    else:\n",
    "        raise Exception(\"Invalid search type\")\n",
    "\n",
    "    # If siteSearch is not empty, search only in the specified site\n",
    "    if siteSearch:\n",
    "        params[\"siteSearch\"] = siteSearch\n",
    "        params[\"siteSearchFilter\"] = \"i\"\n",
    "\n",
    "    # Make request\n",
    "    response = requests.get(url, params=params).json()\n",
    "\n",
    "    # Get total number of results if the request was successful\n",
    "    try:\n",
    "        total_results = response['searchInformation']['totalResults']\n",
    "    except:\n",
    "        print(params)\n",
    "        print(response)\n",
    "        raise Exception(\"Erro na requisição\")\n",
    "\n",
    "    return response, int(total_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T07:04:00.174224700Z",
     "start_time": "2023-08-13T07:04:00.036888900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_count_from_file(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    counts = []\n",
    "    for k in data:\n",
    "        counts.append([c for _, c in k])\n",
    "\n",
    "    return np.array(counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T07:04:00.179825500Z",
     "start_time": "2023-08-13T07:04:00.178235200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def plot_file(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    counts = []\n",
    "    for k in data:\n",
    "        counts.append([c for _, c in k])\n",
    "    counts = np.array(counts)\n",
    "    count = np.mean(counts, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(range(len(count)), count, color=\"#7ed9fc\")\n",
    "    plt.fill_between(range(len(count)), count - np.std(counts, axis=1), count + np.std(counts, axis=1), color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.plot(range(len(count)), count, color=\"black\")\n",
    "    plt.ylim(0, 1.2 * max(count[3:]))\n",
    "    plt.title(filename)\n",
    "    plt.yticks([])\n",
    "    # plt.yscale('log')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T07:04:00.197234400Z",
     "start_time": "2023-08-13T07:04:00.179825500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def display_snippets(filename, pos=0):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    for i, r in enumerate(data):\n",
    "        m = r[0][0]['items'][pos]\n",
    "        print(f\"-\" * 50)\n",
    "        print(f\"qt: {i+1}, total: {r[0][0]['searchInformation']['totalResults']}\")\n",
    "        print(m['title'])\n",
    "        print(\"\\t\", m['snippet'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T07:04:00.197854400Z",
     "start_time": "2023-08-13T07:04:00.194223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def download_data(laugh_atom='k', start=1, end=25, siteSearch=\"\", searchType=\"exact\", hl=\"pt-BR\", lr=\"lang_pt\", simulations=1):\n",
    "    all_data = []\n",
    "    filepath = f\"{laugh_atom}_{siteSearch.split('.')[0]}_{simulations}s_{start}-{end}\"\n",
    "\n",
    "    for i in range(start, end+1):\n",
    "        string = laugh_atom * i\n",
    "        print(f\"[{i} / {end}] Processing {string}...\")\n",
    "\n",
    "        data = []\n",
    "        for j in range(simulations):\n",
    "            print(f\"  [{j + 1} / {simulations}] Making request for {string}...\")\n",
    "            response, total_results = get_google_search_results(string, siteSearch=siteSearch, searchType=searchType, hl=hl, lr=lr)\n",
    "            data.append((response, total_results))\n",
    "\n",
    "        all_data.append(data)\n",
    "\n",
    "        with open(filepath + \".pkl\", \"wb\") as f:\n",
    "            pickle.dump(all_data, f)\n",
    "\n",
    "        with open(filepath + \"_count.json\", \"w\") as f:\n",
    "            count = get_count_from_file(filepath + \".pkl\")\n",
    "            json.dump(count, f, indent=4)\n",
    "\n",
    "        with open(filepath + \"_texts.json\", \"w\") as f:\n",
    "            texts = [[d['link'] for d in k[0][0]['items']] for k in all_data]\n",
    "            json.dump(texts, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-11T07:45:44.706870200Z",
     "start_time": "2023-08-11T07:45:44.690723800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "download_data(\"ha\", start=1, end=50, siteSearch=\"twitter.com\", simulations=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T07:04:37.946028Z",
     "start_time": "2023-08-13T07:04:37.945519300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
